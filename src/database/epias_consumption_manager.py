"""
EPƒ∞A≈û Consumption Data Collector
Handles fetching, processing, and saving real-time consumption data from EPƒ∞A≈û API
"""

import json
import os
from datetime import datetime, timedelta
from pprint import pprint
from dotenv import load_dotenv
import requests
import pandas as pd

# Import required modules
from database.tgt_manager import TGTManager

load_dotenv(dotenv_path=".env", override=True)

class EPIASConsumptionCollector:
    """Collects real-time consumption data from EPƒ∞A≈û"""
    
    def __init__(self):
        """Initialize with TGT manager and configuration"""
        self.tgt_manager = TGTManager()
        self.consumption_url = os.getenv("REALTIME_CONSUMPTION_URL")
        
        # Headers for data requests - defined here instead of importing
        self.headers_getdata = {
            "Content-Type": "application/json",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        }
    
    def get_realtime_consumption_data(self, start_date, end_date):
        """
        Get real-time consumption data with automatic TGT management
        
        Args:
            start_date (str): Start date in format "2024-09-10T00:00:00+03:00"
            end_date (str): End date in format "2024-09-10T23:00:00+03:00"
            
        Returns:
            dict: API response data or None if failed
        """
        try:
            # Get valid TGT
            tgt = self.tgt_manager.get_valid_tgt()
            if not tgt:
                print("‚ùå Failed to get valid TGT")
                return None
            
            # Prepare headers with TGT
            headers = self.headers_getdata.copy()
            headers["TGT"] = tgt
            
            params = {
                "startDate": start_date,
                "endDate": end_date,
                "regionCode": "TR"
            }
            
            print(f"üì° Requesting data from {start_date} to {end_date}")
            response = requests.post(self.consumption_url, headers=headers, json=params)
            print(f"Data request status: {response.status_code}")
            
            if response.status_code == 200:
                print("‚úÖ Successfully fetched consumption data")
                return response.json()
            elif response.status_code == 401:
                # TGT expired - clear cache and retry once
                print("üîÑ TGT expired (401), clearing cache and retrying...")
                self.tgt_manager.clear_cache()
                
                # Retry with fresh TGT
                fresh_tgt = self.tgt_manager.get_valid_tgt()
                if fresh_tgt:
                    headers["TGT"] = fresh_tgt
                    retry_response = requests.post(self.consumption_url, headers=headers, json=params)
                    
                    if retry_response.status_code == 200:
                        print("‚úÖ Retry successful with fresh TGT")
                        return retry_response.json()
                    else:
                        print(f"‚ùå Retry failed: {retry_response.status_code}")
                        return None
                else:
                    print("‚ùå Failed to get fresh TGT for retry")
                    return None
            else:
                print(f"‚ùå Request failed: {response.status_code} - {response.text}")
                return None
                
        except Exception as e:
            print(f"‚ùå Error fetching consumption data: {e}")
            return None
    
    def process_consumption_data(self, data):
        """Process EPƒ∞A≈û API response into a clean DataFrame with proper timezone"""
        if not data:
            return pd.DataFrame()
        
        try:
            

            if 'items' in data:
                consumption_list = data['items']
                df = pd.DataFrame(consumption_list)
                
                # üîß FIX: Handle timezone properly - don't double convert
                if 'date' in df.columns:
                    # The API already gives us dates with timezone: "2025-08-28T00:00:00+03:00"
                    # Just parse them as-is, don't convert timezone
                    df['datetime'] = pd.to_datetime(df['date'])
                    
                    # DEBUG: Show what we got
                    print(f"üîç First datetime after parsing: {df['datetime'].iloc[0]}")
                    print(f"üîç Timezone info: {df['datetime'].iloc[0].tzinfo}")
                
                # Rename consumption column
                if 'consumption' in df.columns:
                    df = df.rename(columns={'consumption': 'consumption_mwh'})
                
                # Keep only required columns
                columns_to_keep = [col for col in ['datetime', 'consumption_mwh'] if col in df.columns]
                if columns_to_keep:
                    df = df[columns_to_keep]
                else:
                    print(f"‚ö†Ô∏è DataFrame columns: {df.columns.tolist()}")
                    print("‚ùå Required columns missing after processing!")
                    return pd.DataFrame()
                
                # Sort by datetime
                df = df.sort_values('datetime').reset_index(drop=True)
                
                print(f"üìä Processed {len(df)} consumption records")
                print(f"üìÖ Date range: {df['datetime'].min()} to {df['datetime'].max()}")
                
                return df
            else:
                print("‚ö†Ô∏è Unexpected data structure")
                return pd.DataFrame()
            
        except Exception as e:
            print(f"‚ùå Error processing consumption data: {e}")
            return pd.DataFrame()
    
    def save_consumption_to_csv(self, data, filename="consumption_data.csv"):
        """
        Save consumption data to CSV file
        
        Args:
            data (dict): Raw API response
            filename (str): Output CSV filename
        """
        if not data:
            print("No data to save")
            return
        
        try:
            # Process the data
            df = self.process_consumption_data(data)
            
            if not df.empty:
                # Save to CSV
                df.to_csv(filename, index=False, encoding='utf-8')
                print(f"‚úÖ Data saved to {filename}")
                print(f"üìä Saved {len(df)} records")
                
                # Display first few rows
                print("\nFirst 5 rows:")
                print(df.head())
                
                return df
            else:
                print("‚ö†Ô∏è No data to save after processing")
                
        except Exception as e:
            print(f"‚ùå Error saving to CSV: {e}")
            # Fallback: save as JSON
            json_filename = filename.replace('.csv', '.json')
            with open(json_filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            print(f"üìÑ Data saved as JSON instead: {json_filename}")
    
    def get_tgt_status(self):
        """Get current TGT status"""
        return self.tgt_manager.get_tgt_status()
    
    def save_consumption_to_database(self, data):
        """
        Save consumption data to PostgreSQL database
        
        Args:
            data (dict): Raw API response
            
        Returns:
            bool: Success status
        """
        try:
            # Process the data first
            df = self.process_consumption_data(data)
            
            if df.empty:
                print("‚ö†Ô∏è No data to save to database")
                return False
            
            # Import and initialize repository
            from .epias_data_repository import EPIASDataRepository  # ‚Üê Fixed import with relative path
            
            repo = EPIASDataRepository()
            success = repo.save_consumption_data(df)
            repo.close()
            
            if success:
                print(f"‚úÖ Successfully saved {len(df)} records to database")
                return True
            else:
                print("‚ùå Failed to save data to database")
                return False
                
        except Exception as e:
            print(f"‚ùå Error saving to database: {e}")
            import traceback
            traceback.print_exc()
            return False

    def collect_and_save_consumption_data(self, start_date, end_date, save_to_csv=True, save_to_db=True, csv_directory=None):
        """
        Complete workflow: fetch, transform, and save consumption data
        
        Args:
            start_date (str): Start date in ISO format
            end_date (str): End date in ISO format  
            save_to_csv (bool): Whether to save CSV file
            save_to_db (bool): Whether to save to database
            csv_directory (str): Directory to save CSV files (optional)
        
        Returns:
            pd.DataFrame: Processed consumption data
        """
        print(f"üöÄ Starting EPƒ∞A≈û data collection for {start_date} to {end_date}")
        
        # Fetch data from API
        raw_data = self.get_realtime_consumption_data(start_date, end_date)
        
        if not raw_data:
            print("‚ùå Failed to fetch data from API")
            return pd.DataFrame()
        
        # Process data
        df = self.process_consumption_data(raw_data)
        
        if df.empty:
            print("‚ùå No data after processing")
            return df
        
        # Show statistics from API response
        if 'statistics' in raw_data:
            stats = raw_data['statistics']
            print(f"\nüìä API Statistics:")
            print(f"  Total Consumption: {stats.get('consumptionTotal', 0):,.2f} MWh")
            print(f"  Average: {stats.get('consumptionAvg', 0):,.2f} MWh")
            print(f"  Min: {stats.get('consumptionMin', 0):,.2f} MWh")
            print(f"  Max: {stats.get('consumptionMax', 0):,.2f} MWh")
        
        # Save to CSV if requested
        if save_to_csv and not df.empty:
            # Use custom directory if provided
            if csv_directory:
                csv_filename = os.path.join(csv_directory, f"epias_consumption_{start_date[:10].replace('-', '')}.csv")
            else:
                csv_filename = f"epias_consumption_{start_date[:10].replace('-', '')}.csv"
            
            df.to_csv(csv_filename, index=False)
            print(f"üíæ CSV saved: {csv_filename}")
        
        # Save to database if requested
        if save_to_db:
            self.save_consumption_to_database(raw_data)
        
        return df


# Test function for the collector
def test_collector():
    """Test function for the EPƒ∞A≈û consumption collector"""
    collector = EPIASConsumptionCollector()
    
    # Test dates - get yesterday's data
    yesterday = datetime.now() - timedelta(days=1)
    start_date = yesterday.strftime("%Y-%m-%dT00:00:00+03:00")
    end_date = yesterday.strftime("%Y-%m-%dT23:00:00+03:00")
    
    print(f"üß™ Testing EPƒ∞A≈û collector for: {start_date} to {end_date}")
    
    # Test the collector
    df = collector.collect_and_save_consumption_data(
        start_date=start_date,
        end_date=end_date,
        save_to_csv=True,
        save_to_db=True
    )
    
    if not df.empty:
        print(f"‚úÖ Test successful: {len(df)} records collected")
    else:
        print("‚ùå Test failed: No data collected")
    
    return df


if __name__ == "__main__":
    test_collector()